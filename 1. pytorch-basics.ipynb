{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ca7e8da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vivek\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "C:\\Users\\vivek\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.2' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "71a35a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.1+cpu\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "print(torch.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a4f989",
   "metadata": {},
   "source": [
    "## Important Tensor Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0450821d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "36fefb3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "efcd7262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eye(4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0597504c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7576, 0.2793, 0.4031, 0.7347],\n",
       "        [0.0293, 0.7999, 0.3971, 0.7544],\n",
       "        [0.5695, 0.4388, 0.6387, 0.5247],\n",
       "        [0.6826, 0.3051, 0.4635, 0.4550]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bfd2e509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6970, -1.1608,  0.6995,  0.1991],\n",
       "        [ 0.8657,  0.2444, -0.6629,  0.8073],\n",
       "        [ 1.1017, -0.1759, -2.2456, -1.4465],\n",
       "        [ 0.0612, -0.6177, -0.7981, -0.1316]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(4,4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6971908d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.3000, 0.6000, 0.9000, 1.2000, 1.5000, 1.8000, 2.1000, 2.4000,\n",
       "        2.7000])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(0, 3, step=0.3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfd2f8d",
   "metadata": {},
   "source": [
    "## Matrix Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5b4f1231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.4212, -0.5107, -1.5727, -0.1232,  3.5870],\n",
       "         [-1.8313,  1.5987, -1.2770,  0.3255, -0.4791],\n",
       "         [ 1.3790,  2.5286,  0.4107, -0.9880, -0.9081]]),\n",
       " tensor([[-0.0255, -1.0233, -0.5962, -1.0055, -0.2106],\n",
       "         [-0.0075,  1.6734,  0.0103, -0.7040, -1.4746],\n",
       "         [-0.3416, -0.3003,  1.3075, -1.1628,  0.1196],\n",
       "         [-0.1631,  0.6614, -0.9301,  1.4301,  0.4208],\n",
       "         [-0.3538,  0.7639, -0.5890, -0.7636,  1.3352]]),\n",
       " tensor([[ 0.5423, -0.5581, -0.3964],\n",
       "         [ 1.4130, -2.6119, -1.6396],\n",
       "         [ 2.3906, -0.5024,  0.0476],\n",
       "         [-1.1322, -0.0179,  0.1280],\n",
       "         [-0.5552, -0.4575, -1.9599]]))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x11 = torch.randn(3,5)\n",
    "x12 = torch.randn(5,5)\n",
    "x13 = torch.randn(5,3)\n",
    "x11, x12, x13\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "08f07d94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6972,  2.7073, -3.8084, -0.3035,  5.3911],\n",
       "        [ 0.5873,  4.7820, -0.5820,  3.0323, -2.6273],\n",
       "        [ 0.2879,  1.3496,  1.1948, -4.3638, -5.5980]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(x11,x12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "34360d88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6972,  2.7073, -3.8084, -0.3035,  5.3911],\n",
       "        [ 0.5873,  4.7820, -0.5820,  3.0323, -2.6273],\n",
       "        [ 0.2879,  1.3496,  1.1948, -4.3638, -5.5980]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x11.mm(x12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d5dc7486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6972,  2.7073, -3.8084, -0.3035,  5.3911],\n",
       "        [ 0.5873,  4.7820, -0.5820,  3.0323, -2.6273],\n",
       "        [ 0.2879,  1.3496,  1.1948, -4.3638, -5.5980]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(x11,x12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0726777f",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (3) must match the size of tensor b (5) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11652/541914409.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx11\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx12\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (3) must match the size of tensor b (5) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "torch.mul(x11,x12)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "388ff673",
   "metadata": {},
   "source": [
    "torch.mm - performs a matrix multiplication without broadcasting - (2D tensor) by (2D tensor)\n",
    "\n",
    "torch.mul - performs a elementwise multiplication with broadcasting - (Tensor) by (Tensor or Number)\n",
    "\n",
    "torch.matmul - matrix product with broadcasting - (Tensor) by (Tensor) with different behaviors depending on the tensor shapes (dot product, matrix product, batched matrix products).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "51cdee0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x14 = torch.randn(3, 4)\n",
    "v = torch.randn(4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1d510b7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-3.8167, -0.9935, -3.4006])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mv(x14,v) ## matrix vector product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7ddc0165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 5])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x15 = torch.randn(10,3,4)\n",
    "x16 = torch.randn(10,4,5)\n",
    "\n",
    "torch.bmm(x15, x16).size()\n",
    "# Performs a batch matrix-matrix product of matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ddc14b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "939aee8a",
   "metadata": {},
   "source": [
    "## Tensor vs Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e6535003",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e455705a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-1.0361,  0.0602],\n",
       "         [-1.6259,  0.4273]]),\n",
       " tensor([[-1.0361,  0.0602],\n",
       "         [-1.6259,  0.4273]], requires_grad=True))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor=torch.randn(2,2)\n",
    "x=Variable(tensor,requires_grad=True)\n",
    "\n",
    "tensor, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5c352e6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-2.1745, grad_fn=<SumBackward0>),\n",
       " tensor([[   nan, 0.2453],\n",
       "         [   nan, 0.6537]], grad_fn=<SqrtBackward0>),\n",
       " tensor([[1.0734, 0.0036],\n",
       "         [2.6437, 0.1826]], grad_fn=<PowBackward0>),\n",
       " tensor([[-1.0361,  0.0602],\n",
       "         [-1.6259,  0.4273]], requires_grad=True))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.sum(),x.sqrt(), x**2, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "31117409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0361,  0.0602],\n",
       "        [-1.6259,  0.4273]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9129d18f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4ad2338f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "30920ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ed936b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vivek\\AppData\\Local\\Temp/ipykernel_11652/2818851177.py:1: UserWarning: volatile was removed (Variable.volatile is always False)\n",
      "  x.volatile\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.volatile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "278ba599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True False\n"
     ]
    }
   ],
   "source": [
    "x = Variable(torch.FloatTensor([13.]),requires_grad=True)\n",
    "\n",
    "y = x**3 + 3\n",
    "\n",
    "z = Variable(torch.FloatTensor([5.]))\n",
    "\n",
    "print(x.requires_grad,z.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4aca12f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.grad_fn.next_functions[0][0]\n",
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b001c257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([13.], requires_grad=True), tensor([507.]))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "21b295f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.]), tensor([0.]), tensor([0.]))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad,x.grad.data.zero_(), x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "970e7231",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = Variable(torch.ones(2), requires_grad = True)\n",
    "x2 = Variable(torch.ones(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0ace249a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 3.], grad_fn=<AddBackward0>)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "y = x1 * 2 + x2\n",
    "print(y)\n",
    "print(y.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "263cb665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 2.])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.backward(torch.Tensor([1,1]))\n",
    "\n",
    "x1.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "78357b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "x2.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6282d707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0.])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.grad.data.zero_() ## sets gradients to zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb508472",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da0e0a7f",
   "metadata": {},
   "source": [
    "## Simple 1D example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0420f0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.tensor(1.,requires_grad=True)\n",
    "w=torch.tensor(2.,requires_grad=True)\n",
    "b=torch.tensor(2.,requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f801fa6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('torch.FloatTensor', torch.Size([]), 1)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.type(),x.size(),x.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "717b7782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1., requires_grad=True)\n",
      "tensor(2., requires_grad=True)\n",
      "tensor(2., requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(w)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0f5bb99f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4., grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y=w*x+b\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3fa26620",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.backward(retain_graph=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b991403f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1., requires_grad=True)\n",
      "tensor(2., requires_grad=True)\n",
      "tensor(2., requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(w)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83207654",
   "metadata": {},
   "source": [
    "## Simple 2 D example with a Linear layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0d343afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w Parameter containing:\n",
      "tensor([[-0.2229, -0.4551, -0.4546],\n",
      "        [ 0.3503,  0.5745,  0.2357]], requires_grad=True)\n",
      "b Parameter containing:\n",
      "tensor([0.2774, 0.4527], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x=torch.randn(10,3)\n",
    "y=torch.rand(10,2)\n",
    "\n",
    "linear=nn.Linear(3,2)\n",
    "\n",
    "print('w',linear.weight)\n",
    "print('b',linear.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2ef8a751",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion=nn.MSELoss()\n",
    "optimizer=torch.optim.SGD(linear.parameters(),lr=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "682d495a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss initially 0.5654733777046204\n"
     ]
    }
   ],
   "source": [
    "pred=linear(x)\n",
    "loss=criterion(pred,y)\n",
    "\n",
    "print('loss initially',loss.item()) ## get value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3ac30b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3eb874cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0537, -0.4483, -0.8926],\n",
      "        [ 0.0576,  0.4482,  0.3318]])\n",
      "tensor([-0.2893, -0.0351])\n"
     ]
    }
   ],
   "source": [
    "print(linear.weight.grad)\n",
    "print(linear.bias.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ac0a7541",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step() ## 1-step gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a656b202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss after 1 epoch 0.5515884160995483\n"
     ]
    }
   ],
   "source": [
    "pred=linear(x)\n",
    "loss=criterion(pred,y)\n",
    "\n",
    "print('loss after 1 epoch',loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "36ad573c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss after 2 epoch 0.537927508354187\n"
     ]
    }
   ],
   "source": [
    "optimizer.step()\n",
    "\n",
    "pred=linear(x)\n",
    "loss=criterion(pred,y)\n",
    "\n",
    "print('loss after 2 epoch',loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0afd91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2cea1335",
   "metadata": {},
   "source": [
    "## From Numpy to Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f6cd505d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]], dtype=torch.int32)\n",
      "[[1 2]\n",
      " [3 4]]\n"
     ]
    }
   ],
   "source": [
    "x=np.array([[1,2],[3,4]])\n",
    "\n",
    "y=torch.from_numpy(x)\n",
    "\n",
    "print(y)\n",
    "\n",
    "z=y.numpy()\n",
    "\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec09cb6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ddf96948",
   "metadata": {},
   "source": [
    "## Input Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2d23eb4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../../data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 170498071/170498071 [01:42<00:00, 1670685.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../../data/cifar-10-python.tar.gz to ../../data/\n",
      "torch.Size([3, 32, 32])\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "train_dataset = torchvision.datasets.CIFAR10(root='../../data/',\n",
    "                                             train=True, \n",
    "                                             transform=transforms.ToTensor(),\n",
    "                                             download=True)\n",
    "\n",
    "# Fetch one data pair (read data from disk).\n",
    "image, label = train_dataset[0]\n",
    "print (image.size())\n",
    "print (label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900ceaa3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "90fde39b",
   "metadata": {},
   "source": [
    "# You should build your custom dataset as below.\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self):\n",
    "        # TODO\n",
    "        # 1. Initialize file paths or a list of file names. \n",
    "        pass\n",
    "    def __getitem__(self, index):\n",
    "        # TODO\n",
    "        # 1. Read one data from file (e.g. using numpy.fromfile, PIL.Image.open).\n",
    "        # 2. Preprocess the data (e.g. torchvision.Transform).\n",
    "        # 3. Return a data pair (e.g. image and label).\n",
    "        pass\n",
    "    def __len__(self):\n",
    "        # You should change 0 to the total size of your dataset.\n",
    "        return 0 \n",
    "\n",
    "# You can then use the prebuilt data loader. \n",
    "custom_dataset = CustomDataset()\n",
    "train_loader = torch.utils.data.DataLoader(dataset=custom_dataset,\n",
    "                                           batch_size=64, \n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958abf9d",
   "metadata": {},
   "source": [
    "## Finetuning a pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3813b729",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vivek\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vivek\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to C:\\Users\\vivek/.cache\\torch\\hub\\checkpoints\\resnet18-f37072fd.pth\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 44.7M/44.7M [00:11<00:00, 4.11MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 100])\n"
     ]
    }
   ],
   "source": [
    "resnet = torchvision.models.resnet18(pretrained=True)\n",
    "\n",
    "# If you want to finetune only the top layer of the model, set as below.\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace the top layer for finetuning.\n",
    "resnet.fc = nn.Linear(resnet.fc.in_features, 100)  # 100 is an example.\n",
    "\n",
    "# Forward pass.\n",
    "images = torch.randn(64, 3, 224, 224)\n",
    "outputs = resnet(images)\n",
    "print (outputs.size())     # (64, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4123ccaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d76637",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
